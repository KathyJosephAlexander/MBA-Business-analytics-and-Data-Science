{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09.Ensemble Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
        "x = dataset.iloc[:, [2, 3]].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "Psv9NEI1hpMI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import  VotingClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "clf1 = LogisticRegression()\n",
        "clf2 = tree.DecisionTreeClassifier()\n",
        "clf3 = svm.SVC()\n",
        "clf4 = RandomForestClassifier()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('svm', clf3)])\n",
        "s = cross_val_score(eclf, x, y, scoring = 'accuracy', cv = kf)\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0awvAaNYMGD",
        "outputId": "cfef2c77-0929-4c9c-c463-4ee3dd3da867"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7   0.9   1.    0.975 0.925 0.825 0.625 0.575 0.675 0.3  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy:',sum(s)/len(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iN3Osh1pABL",
        "outputId": "fc8e46d6-cf4e-4c41-86ec-3ea48c686f1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "logreg_bagging_model = BaggingClassifier(base_estimator=clf1, n_estimators=50, random_state=12)"
      ],
      "metadata": {
        "id": "UUC7LjVHgxDT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_bagging_model = BaggingClassifier(base_estimator=clf1, n_estimators=50, random_state=12)\n",
        "dtree_bagging_model = BaggingClassifier(base_estimator=clf2, n_estimators=50, random_state=12)\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=12)\n",
        "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=12)\n",
        "\n",
        "def bagging_ensemble(model):\n",
        "    k_folds = KFold(n_splits=20)\n",
        "    results = cross_val_score(model, x,y, cv=k_folds)\n",
        "    print(results.mean())\n",
        "\n",
        "bagging_ensemble(logreg_bagging_model)\n",
        "bagging_ensemble(dtree_bagging_model)\n",
        "bagging_ensemble(random_forest)\n",
        "bagging_ensemble(extra_trees)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afx2OjxmkgvU",
        "outputId": "ddee6479-bc0e-4c0b-e220-0a15ec18ea13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6424999999999998\n",
            "0.8899999999999999\n",
            "0.8874999999999998\n",
            "0.8775000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_folds = KFold(n_splits=20)\n",
        "\n",
        "num_estimators = [20, 40, 60, 80, 100]\n",
        "\n",
        "for i in num_estimators:\n",
        "    ada_boost = AdaBoostClassifier(n_estimators=i)\n",
        "    results = cross_val_score(ada_boost, x,y, cv=k_folds)\n",
        "    print(\"Results for {} estimators:\".format(i))\n",
        "    print(results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KZZSIs1mmrV",
        "outputId": "bb022d93-cf62-4a1e-88a7-a2e68ec300e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 20 estimators:\n",
            "0.8674999999999999\n",
            "Results for 40 estimators:\n",
            "0.8699999999999999\n",
            "Results for 60 estimators:\n",
            "0.8724999999999999\n",
            "Results for 80 estimators:\n",
            "0.8700000000000001\n",
            "Results for 100 estimators:\n",
            "0.8700000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "k_folds = KFold(n_splits=20)\n",
        "\n",
        "num_estimators = [20, 40, 60, 80, 100]\n",
        "\n",
        "for i in num_estimators:\n",
        "    ada_boost = GradientBoostingClassifier(n_estimators=i)\n",
        "    results = cross_val_score(ada_boost, x,y, cv=k_folds)\n",
        "    print(\"Results for {} estimators:\".format(i))\n",
        "    print(results.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQpaCjcGlns_",
        "outputId": "6ea7d114-525a-45e7-f525-76a7a731625f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 20 estimators:\n",
            "0.9075\n",
            "Results for 40 estimators:\n",
            "0.9149999999999998\n",
            "Results for 60 estimators:\n",
            "0.8974999999999997\n",
            "Results for 80 estimators:\n",
            "0.8925000000000001\n",
            "Results for 100 estimators:\n",
            "0.8999999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVX39BuMnAH3"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}